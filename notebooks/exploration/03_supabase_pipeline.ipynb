{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supabase Digital Channels Pipeline for Banking Churn POC\n",
    "\n",
    "This notebook handles the Supabase digital channels data pipeline for the Apex National Bank churn prediction POC.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Supabase serves as our **Mobile Banking App Backend**, containing:\n",
    "- **Sessions** - App login/logout events with device info\n",
    "- **Events** - User actions (view balance, transfer, bill pay, etc.)\n",
    "\n",
    "## Churn Signal Logic\n",
    "\n",
    "Digital engagement strongly predicts churn:\n",
    "\n",
    "| Segment | App Usage | Rationale |\n",
    "|---------|-----------|----------|\n",
    "| Active | Regular logins, multiple features | Engaged customers stay |\n",
    "| At-Risk | Declining app usage | Disengagement signals risk |\n",
    "| Churned | Stopped using app before closing | Early warning sign |\n",
    "\n",
    "## Entity Resolution\n",
    "\n",
    "Customers are linked via **email**:\n",
    "\n",
    "```\n",
    "ERPNext (email_id) <---> Supabase (user_email)\n",
    "```\n",
    "\n",
    "## Notebook Sections\n",
    "\n",
    "1. **Configuration** - Environment setup and credentials\n",
    "2. **Supabase Client** - REST API wrapper\n",
    "3. **Exploration** - Check existing tables\n",
    "4. **Data Ingestion** - Create app sessions and events\n",
    "5. **Data Extraction** - Export to CSV/JSON for Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. Supabase project created at https://supabase.com\n",
    "2. Tables created (app_sessions, app_events)\n",
    "3. Credentials in `docs/.env` file (auto-loaded)\n",
    "\n",
    "### Credentials File Format\n",
    "\n",
    "```powershell\n",
    "$env:SUPABASE_URL = \"https://xxxxx.supabase.co\"\n",
    "$env:SUPABASE_KEY = \"your-anon-key\"\n",
    "$env:SUPABASE_SECRET = \"your-service-role-key\"\n",
    "```\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "```bash\n",
    "pip install supabase\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing supabase...\n",
      "Collecting supabase\n",
      "  Downloading supabase-2.27.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting realtime==2.27.1 (from supabase)\n",
      "  Downloading realtime-2.27.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting supabase-functions==2.27.1 (from supabase)\n",
      "  Downloading supabase_functions-2.27.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting storage3==2.27.1 (from supabase)\n",
      "  Downloading storage3-2.27.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting supabase-auth==2.27.1 (from supabase)\n",
      "  Downloading supabase_auth-2.27.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting postgrest==2.27.1 (from supabase)\n",
      "  Downloading postgrest-2.27.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.26 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from supabase) (0.28.1)\n",
      "Collecting yarl>=1.22.0 (from supabase)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl.metadata (77 kB)\n",
      "Collecting deprecation>=2.1.0 (from postgrest==2.27.1->supabase)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.9 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from postgrest==2.27.1->supabase) (2.11.7)\n",
      "Collecting typing-extensions>=4.14.0 (from realtime==2.27.1->supabase)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: websockets<16,>=11 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from realtime==2.27.1->supabase) (15.0.1)\n",
      "Collecting pyiceberg>=0.10.0 (from storage3==2.27.1->supabase)\n",
      "  Downloading pyiceberg-0.10.0.tar.gz (842 kB)\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ------------ --------------------------- 262.1/842.6 kB ? eta -:--:--\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ----------------------- ------------- 524.3/842.6 kB 62.1 kB/s eta 0:00:06\n",
      "     ---------------------------------- -- 786.4/842.6 kB 42.2 kB/s eta 0:00:02\n",
      "     ---------------------------------- -- 786.4/842.6 kB 42.2 kB/s eta 0:00:02\n",
      "     ---------------------------------- -- 786.4/842.6 kB 42.2 kB/s eta 0:00:02\n",
      "     ---------------------------------- -- 786.4/842.6 kB 42.2 kB/s eta 0:00:02\n",
      "     ---------------------------------------- 842.6/842.6 kB 43.5 kB/s  0:00:15\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (2.10.1)\n",
      "Collecting strenum>=0.4.15 (from supabase-functions==2.27.1->supabase)\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<0.29,>=0.26->postgrest==2.27.1->supabase)\n",
      "  Downloading h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==2.27.1->supabase)\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==2.27.1->supabase)\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0,>=1.9->postgrest==2.27.1->supabase) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0,>=1.9->postgrest==2.27.1->supabase) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0,>=1.9->postgrest==2.27.1->supabase) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sulaimanahmed\\appdata\\roaming\\python\\python313\\site-packages (from deprecation>=2.1.0->postgrest==2.27.1->supabase) (24.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=5.5 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (5.5.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (8.2.1)\n",
      "Requirement already satisfied: fsspec>=2023.1.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2025.5.1)\n",
      "Requirement already satisfied: mmh3<6.0.0,>=4.0.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (5.1.0)\n",
      "Requirement already satisfied: pyparsing<4.0.0,>=3.1.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (3.2.3)\n",
      "Collecting pyroaring<2.0.0,>=1.0.0 (from pyiceberg>=0.10.0->storage3==2.27.1->supabase)\n",
      "  Downloading pyroaring-1.0.3-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.20.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2.32.3)\n",
      "Requirement already satisfied: rich<15.0.0,>=10.11.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (14.0.0)\n",
      "Requirement already satisfied: sortedcontainers==2.4.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2.4.0)\n",
      "Collecting strictyaml<2.0.0,>=1.7.0 (from pyiceberg>=0.10.0->storage3==2.27.1->supabase)\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (9.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sulaimanahmed\\appdata\\roaming\\python\\python313\\site-packages (from click<9.0.0,>=7.1.1->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.20.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.20.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sulaimanahmed\\appdata\\roaming\\python\\python313\\site-packages (from rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in c:\\users\\sulaimanahmed\\appdata\\roaming\\python\\python313\\site-packages (from strictyaml<2.0.0,>=1.7.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2.9.0.post0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (0.1.2)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (45.0.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.14->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sulaimanahmed\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.6.0->strictyaml<2.0.0,>=1.7.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (1.17.0)\n",
      "Requirement already satisfied: multidict>=4.0 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yarl>=1.22.0->supabase) (6.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.1 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yarl>=1.22.0->supabase) (0.3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sulaimanahmed\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
      "Downloading supabase-2.27.1-py3-none-any.whl (16 kB)\n",
      "Downloading postgrest-2.27.1-py3-none-any.whl (21 kB)\n",
      "Downloading realtime-2.27.1-py3-none-any.whl (22 kB)\n",
      "Downloading storage3-2.27.1-py3-none-any.whl (27 kB)\n",
      "Downloading supabase_auth-2.27.1-py3-none-any.whl (48 kB)\n",
      "Downloading supabase_functions-2.27.1-py3-none-any.whl (8.5 kB)\n",
      "Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pyroaring-1.0.3-cp313-cp313-win_amd64.whl (260 kB)\n",
      "Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading yarl-1.22.0-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Building wheels for collected packages: pyiceberg\n",
      "  Building wheel for pyiceberg (pyproject.toml): started\n",
      "  Building wheel for pyiceberg (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyiceberg: filename=pyiceberg-0.10.0-cp313-cp313-win_amd64.whl size=588566 sha256=8357d7ea8f4a72465b8957de3c85dda9aa658d7a67c15b19318de587330be97d\n",
      "  Stored in directory: c:\\users\\sulaimanahmed\\appdata\\local\\pip\\cache\\wheels\\94\\e1\\ad\\72718f6a4b508a4dcd74f62431dc44240ca3518c3837f58600\n",
      "Successfully built pyiceberg\n",
      "Installing collected packages: strenum, pyroaring, yarl, typing-extensions, hyperframe, hpack, deprecation, strictyaml, h2, supabase-functions, supabase-auth, realtime, pyiceberg, postgrest, storage3, supabase\n",
      "\n",
      "  Attempting uninstall: yarl\n",
      "\n",
      "    Found existing installation: yarl 1.20.1\n",
      "\n",
      "    Uninstalling yarl-1.20.1:\n",
      "\n",
      "      Successfully uninstalled yarl-1.20.1\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.13.2\n",
      "\n",
      "    Uninstalling typing_extensions-4.13.2:\n",
      "\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.13.2\n",
      "   ------- --------------------------------  3/16 [typing-extensions]\n",
      "   ---------- -----------------------------  4/16 [hyperframe]\n",
      "   ----------------- ----------------------  7/16 [strictyaml]\n",
      "   ----------------- ----------------------  7/16 [strictyaml]\n",
      "   ------------------------- -------------- 10/16 [supabase-auth]\n",
      "   ------------------------------ --------- 12/16 [pyiceberg]\n",
      "   ------------------------------ --------- 12/16 [pyiceberg]\n",
      "   ------------------------------ --------- 12/16 [pyiceberg]\n",
      "   ------------------------------ --------- 12/16 [pyiceberg]\n",
      "   ------------------------------ --------- 12/16 [pyiceberg]\n",
      "   ------------------------------------- -- 15/16 [supabase]\n",
      "   ---------------------------------------- 16/16 [supabase]\n",
      "\n",
      "Successfully installed deprecation-2.1.0 h2-4.3.0 hpack-4.1.0 hyperframe-6.1.0 postgrest-2.27.1 pyiceberg-0.10.0 pyroaring-1.0.3 realtime-2.27.1 storage3-2.27.1 strenum-0.4.15 strictyaml-1.7.3 supabase-2.27.1 supabase-auth-2.27.1 supabase-functions-2.27.1 typing-extensions-4.15.0 yarl-1.22.0\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "# Install supabase if not present\n",
    "try:\n",
    "    from supabase import create_client, Client\n",
    "    print(\"supabase already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing supabase...\")\n",
    "    !pip install supabase\n",
    "    from supabase import create_client, Client\n",
    "    print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Required packages\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11 credentials from ..\\..\\docs\\.env\n",
      "\n",
      "Configuration loaded!\n",
      "  URL: https://wtdspfddzqkpdaokgzys.supabase.co\n",
      "  Key: sb_publishable_nDRxk...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Auto-load from .env file\n",
    "# =============================================================================\n",
    "\n",
    "def load_env_file(env_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load credentials from .env file (PowerShell format).\n",
    "    \"\"\"\n",
    "    credentials = {}\n",
    "    try:\n",
    "        with open(env_path, 'r') as f:\n",
    "            for line in f:\n",
    "                match = re.match(r'\\$env:(\\w+)\\s*=\\s*[\"\\']([^\"\\']*)[\"\\']', line.strip())\n",
    "                if match:\n",
    "                    var_name, value = match.groups()\n",
    "                    credentials[var_name] = value\n",
    "        print(f\"Loaded {len(credentials)} credentials from {env_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {env_path} not found, using environment variables\")\n",
    "    return credentials\n",
    "\n",
    "# Load from .env file\n",
    "ENV_FILE = Path(\"../../docs/.env\")\n",
    "env_creds = load_env_file(str(ENV_FILE))\n",
    "\n",
    "# Supabase Credentials\n",
    "SUPABASE_URL = env_creds.get(\"SUPABASE_URL\", os.getenv(\"SUPABASE_URL\", \"\"))\n",
    "SUPABASE_KEY = env_creds.get(\"SUPABASE_KEY\", os.getenv(\"SUPABASE_KEY\", \"\"))\n",
    "SUPABASE_SECRET = env_creds.get(\"SUPABASE_SECRET\", os.getenv(\"SUPABASE_SECRET\", \"\"))\n",
    "\n",
    "# Data paths\n",
    "ERP_CUSTOMERS_PATH = Path(\"../../data/raw/erp_customers.csv\")\n",
    "OUTPUT_DIR = Path(\"../../data/raw\")\n",
    "\n",
    "# Date range (same as other systems)\n",
    "START_DATE = datetime(2023, 1, 1)\n",
    "END_DATE = datetime(2026, 1, 11)\n",
    "\n",
    "# Check credentials\n",
    "creds_set = all([SUPABASE_URL, SUPABASE_KEY])\n",
    "\n",
    "if creds_set:\n",
    "    print(f\"\\nConfiguration loaded!\")\n",
    "    print(f\"  URL: {SUPABASE_URL}\")\n",
    "    print(f\"  Key: {SUPABASE_KEY[:20]}...\")\n",
    "else:\n",
    "    print(\"WARNING: Supabase credentials not set!\")\n",
    "    print(\"\\nAdd to docs/.env:\")\n",
    "    print('  $env:SUPABASE_URL = \"your-url\"')\n",
    "    print('  $env:SUPABASE_KEY = \"your-key\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference data loaded:\n",
      "  Event types: 10\n",
      "  Device types: 4\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# REFERENCE DATA\n",
    "# =============================================================================\n",
    "\n",
    "# App event types for mobile banking\n",
    "EVENT_TYPES = [\n",
    "    {\"type\": \"view_balance\", \"weight\": 30},      # Most common\n",
    "    {\"type\": \"view_transactions\", \"weight\": 20},\n",
    "    {\"type\": \"transfer_internal\", \"weight\": 15},\n",
    "    {\"type\": \"transfer_external\", \"weight\": 5},\n",
    "    {\"type\": \"bill_payment\", \"weight\": 10},\n",
    "    {\"type\": \"card_controls\", \"weight\": 5},\n",
    "    {\"type\": \"view_statements\", \"weight\": 5},\n",
    "    {\"type\": \"update_profile\", \"weight\": 3},\n",
    "    {\"type\": \"contact_support\", \"weight\": 2},     # Less common\n",
    "    {\"type\": \"apply_product\", \"weight\": 5},\n",
    "]\n",
    "\n",
    "# Device types\n",
    "DEVICES = [\n",
    "    {\"type\": \"iPhone\", \"platform\": \"iOS\", \"weight\": 45},\n",
    "    {\"type\": \"Android Phone\", \"platform\": \"Android\", \"weight\": 40},\n",
    "    {\"type\": \"iPad\", \"platform\": \"iOS\", \"weight\": 10},\n",
    "    {\"type\": \"Android Tablet\", \"platform\": \"Android\", \"weight\": 5},\n",
    "]\n",
    "\n",
    "# App versions\n",
    "APP_VERSIONS = [\"3.0.1\", \"3.1.0\", \"3.2.0\", \"3.2.1\", \"4.0.0\", \"4.1.0\"]\n",
    "\n",
    "print(f\"Reference data loaded:\")\n",
    "print(f\"  Event types: {len(EVENT_TYPES)}\")\n",
    "print(f\"  Device types: {len(DEVICES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Supabase Client\n",
    "\n",
    "Connect to Supabase using the official Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Supabase!\n",
      "  URL: https://wtdspfddzqkpdaokgzys.supabase.co\n"
     ]
    }
   ],
   "source": [
    "def connect_supabase() -> Client:\n",
    "    \"\"\"\n",
    "    Connect to Supabase using the Python client.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use service role key for admin operations\n",
    "        key_to_use = SUPABASE_SECRET if SUPABASE_SECRET else SUPABASE_KEY\n",
    "        supabase: Client = create_client(SUPABASE_URL, key_to_use)\n",
    "        print(f\"Connected to Supabase!\")\n",
    "        print(f\"  URL: {SUPABASE_URL}\")\n",
    "        return supabase\n",
    "    except Exception as e:\n",
    "        print(f\"Connection error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Connect\n",
    "if creds_set:\n",
    "    supabase = connect_supabase()\n",
    "else:\n",
    "    print(\"Skipping connection - credentials not set\")\n",
    "    supabase = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Exploration\n",
    "\n",
    "Check existing data in Supabase tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Supabase Data Survey\n",
      "URL: https://wtdspfddzqkpdaokgzys.supabase.co\n",
      "============================================================\n",
      "  app_sessions         :      0 records\n",
      "  app_events           :      0 records\n"
     ]
    }
   ],
   "source": [
    "def explore_supabase(supabase: Client):\n",
    "    \"\"\"\n",
    "    Survey existing data in Supabase.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Supabase Data Survey\")\n",
    "    print(f\"URL: {SUPABASE_URL}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    tables = [\"app_sessions\", \"app_events\"]\n",
    "    \n",
    "    for table in tables:\n",
    "        try:\n",
    "            result = supabase.table(table).select(\"*\", count=\"exact\").limit(1).execute()\n",
    "            count = result.count if result.count else 0\n",
    "            print(f\"  {table:20} : {count:6} records\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {table:20} : Error - {str(e)[:50]}\")\n",
    "\n",
    "# Run exploration\n",
    "if supabase:\n",
    "    explore_supabase(supabase)\n",
    "else:\n",
    "    print(\"Not connected to Supabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ERPNext Customers (to link)\n",
      "============================================================\n",
      "\n",
      "Loaded 502 customers from ERPNext\n",
      "\n",
      "Segment distribution:\n",
      "website\n",
      "active     311\n",
      "at_risk    126\n",
      "churned     63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample customers:\n",
      "     customer_name                 email_id  website\n",
      "0  Adnan Ahmed 831  adnan.ahmed31@gmail.com   active\n",
      "1  Adnan Begum 248  adnan.begum45@gmail.com   active\n",
      "2  Adnan Begum 595  adnan.begum26@gmail.com   active\n",
      "3  Adnan Malik 605  adnan.malik70@gmail.com  at_risk\n",
      "4  Adnan Malik 886  adnan.malik79@gmail.com   active\n"
     ]
    }
   ],
   "source": [
    "# Load ERPNext customers to link digital data\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ERPNext Customers (to link)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if ERP_CUSTOMERS_PATH.exists():\n",
    "    erp_customers = pd.read_csv(ERP_CUSTOMERS_PATH)\n",
    "    \n",
    "    print(f\"\\nLoaded {len(erp_customers)} customers from ERPNext\")\n",
    "    print(f\"\\nSegment distribution:\")\n",
    "    print(erp_customers['website'].value_counts())  # 'website' stores segment\n",
    "    \n",
    "    print(f\"\\nSample customers:\")\n",
    "    print(erp_customers[['customer_name', 'email_id', 'website']].head())\n",
    "else:\n",
    "    print(f\"ERPNext customer file not found: {ERP_CUSTOMERS_PATH}\")\n",
    "    erp_customers = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Ingestion\n",
    "\n",
    "Create mobile app data in Supabase linked to ERPNext customers.\n",
    "\n",
    "### Churn Signal Implementation\n",
    "\n",
    "| Segment | Sessions/Month | Events/Session | Pattern |\n",
    "|---------|----------------|----------------|--------|\n",
    "| Active | 15-30 | 5-15 | Regular usage |\n",
    "| At-Risk | 5-15 | 3-8 | Declining usage |\n",
    "| Churned | 0-5 | 1-3 | Stopped before churn |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n",
      "\n",
      "Sessions by segment:\n",
      "  Active: ~37 sessions\n",
      "  At-Risk: ~28 sessions\n",
      "  Churned: ~8 sessions\n"
     ]
    }
   ],
   "source": [
    "def determine_session_count(segment: str) -> int:\n",
    "    \"\"\"\n",
    "    Determine number of app sessions based on customer segment.\n",
    "    Active customers use the app more frequently.\n",
    "    \"\"\"\n",
    "    if segment == \"churned\":\n",
    "        return random.randint(5, 15)   # Low usage before churning\n",
    "    elif segment == \"at_risk\":\n",
    "        return random.randint(15, 30)  # Declining usage\n",
    "    else:  # active\n",
    "        return random.randint(30, 60)  # Regular usage\n",
    "\n",
    "\n",
    "def determine_events_per_session(segment: str) -> int:\n",
    "    \"\"\"\n",
    "    Determine number of events per session.\n",
    "    Active customers do more per session.\n",
    "    \"\"\"\n",
    "    if segment == \"churned\":\n",
    "        return random.randint(1, 3)    # Quick sessions\n",
    "    elif segment == \"at_risk\":\n",
    "        return random.randint(2, 5)    # Limited engagement\n",
    "    else:  # active\n",
    "        return random.randint(4, 10)   # Full engagement\n",
    "\n",
    "\n",
    "def get_session_dates(segment: str, start: datetime, end: datetime) -> List[datetime]:\n",
    "    \"\"\"\n",
    "    Generate session dates based on segment behavior.\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    num_sessions = determine_session_count(segment)\n",
    "    \n",
    "    if segment == \"churned\":\n",
    "        # Sessions stopped 3-12 months before end\n",
    "        churn_date = end - timedelta(days=random.randint(90, 365))\n",
    "        session_end = churn_date\n",
    "    else:\n",
    "        session_end = end\n",
    "    \n",
    "    # Generate random dates\n",
    "    delta = (session_end - start).days\n",
    "    if delta > 0:\n",
    "        for _ in range(num_sessions):\n",
    "            random_days = random.randint(0, delta)\n",
    "            session_date = start + timedelta(days=random_days)\n",
    "            dates.append(session_date)\n",
    "    \n",
    "    return sorted(dates)\n",
    "\n",
    "\n",
    "def weighted_choice(items: List[Dict]) -> Dict:\n",
    "    \"\"\"Select item based on weight.\"\"\"\n",
    "    total = sum(item['weight'] for item in items)\n",
    "    r = random.uniform(0, total)\n",
    "    cumulative = 0\n",
    "    for item in items:\n",
    "        cumulative += item['weight']\n",
    "        if r <= cumulative:\n",
    "            return item\n",
    "    return items[-1]\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "print(f\"\\nSessions by segment:\")\n",
    "print(f\"  Active: ~{determine_session_count('active')} sessions\")\n",
    "print(f\"  At-Risk: ~{determine_session_count('at_risk')} sessions\")\n",
    "print(f\"  Churned: ~{determine_session_count('churned')} sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sessions_and_events(supabase: Client, erp_customers: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Create app sessions and events for all customers.\n",
    "    \n",
    "    Returns tuple of (sessions_list, events_list) for CSV export.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Creating App Sessions and Events\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_sessions = []\n",
    "    all_events = []\n",
    "    session_errors = 0\n",
    "    event_errors = 0\n",
    "    \n",
    "    segment_stats = {\"active\": 0, \"at_risk\": 0, \"churned\": 0}\n",
    "    \n",
    "    for idx, row in erp_customers.iterrows():\n",
    "        email = row['email_id']\n",
    "        segment = row['website']  # Segment stored in website field\n",
    "        \n",
    "        # Get session dates for this customer\n",
    "        session_dates = get_session_dates(segment, START_DATE, END_DATE)\n",
    "        \n",
    "        for session_date in session_dates:\n",
    "            # Generate session\n",
    "            device = weighted_choice(DEVICES)\n",
    "            session_duration = random.randint(60, 900)  # 1-15 minutes\n",
    "            session_end = session_date + timedelta(seconds=session_duration)\n",
    "            \n",
    "            session_data = {\n",
    "                \"user_email\": email,\n",
    "                \"session_start\": session_date.isoformat(),\n",
    "                \"session_end\": session_end.isoformat(),\n",
    "                \"device_type\": device['type'],\n",
    "                \"platform\": device['platform'],\n",
    "                \"app_version\": random.choice(APP_VERSIONS),\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                # Insert session\n",
    "                result = supabase.table(\"app_sessions\").insert(session_data).execute()\n",
    "                session_id = result.data[0]['id']\n",
    "                \n",
    "                session_data['id'] = session_id\n",
    "                session_data['segment'] = segment\n",
    "                all_sessions.append(session_data)\n",
    "                segment_stats[segment] += 1\n",
    "                \n",
    "                # Generate events for this session\n",
    "                num_events = determine_events_per_session(segment)\n",
    "                \n",
    "                for i in range(num_events):\n",
    "                    event_type = weighted_choice(EVENT_TYPES)\n",
    "                    event_offset = random.randint(0, session_duration)\n",
    "                    event_time = session_date + timedelta(seconds=event_offset)\n",
    "                    \n",
    "                    event_data = {\n",
    "                        \"session_id\": session_id,\n",
    "                        \"user_email\": email,\n",
    "                        \"event_type\": event_type['type'],\n",
    "                        \"event_timestamp\": event_time.isoformat(),\n",
    "                        \"event_data\": json.dumps({\"source\": \"mobile_app\"}),\n",
    "                    }\n",
    "                    \n",
    "                    try:\n",
    "                        supabase.table(\"app_events\").insert(event_data).execute()\n",
    "                        event_data['segment'] = segment\n",
    "                        all_events.append(event_data)\n",
    "                    except Exception as e:\n",
    "                        event_errors += 1\n",
    "                        if event_errors <= 3:\n",
    "                            print(f\"  Event error: {str(e)[:60]}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                session_errors += 1\n",
    "                if session_errors <= 3:\n",
    "                    print(f\"  Session error: {str(e)[:60]}\")\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{len(erp_customers)} customers...\")\n",
    "            print(f\"    Sessions: {len(all_sessions)}, Events: {len(all_events)}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"INGESTION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  Total Sessions: {len(all_sessions)} ({session_errors} errors)\")\n",
    "    print(f\"  Total Events: {len(all_events)} ({event_errors} errors)\")\n",
    "    print(f\"\\nSessions by segment:\")\n",
    "    for seg, count in segment_stats.items():\n",
    "        print(f\"  {seg}: {count} sessions\")\n",
    "    \n",
    "    return all_sessions, all_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Supabase Data Ingestion\n",
      "Target: https://wtdspfddzqkpdaokgzys.supabase.co\n",
      "Customers to process: 502\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Creating App Sessions and Events\n",
      "============================================================\n",
      "  Session error: <ConnectionTerminated error_code:0, last_stream_id:19999, ad\n",
      "  Processed 50/502 customers...\n",
      "    Sessions: 1870, Events: 12014\n",
      "  Event error: <ConnectionTerminated error_code:0, last_stream_id:19999, ad\n",
      "  Processed 100/502 customers...\n",
      "    Sessions: 3604, Events: 22745\n",
      "  Event error: <ConnectionTerminated error_code:0, last_stream_id:19999, ad\n",
      "  Processed 150/502 customers...\n",
      "    Sessions: 5259, Events: 32619\n",
      "  Event error: <ConnectionTerminated error_code:0, last_stream_id:19999, ad\n",
      "  Processed 200/502 customers...\n",
      "    Sessions: 7007, Events: 43317\n",
      "  Processed 250/502 customers...\n",
      "    Sessions: 8794, Events: 54739\n",
      "  Processed 300/502 customers...\n",
      "    Sessions: 10578, Events: 65585\n",
      "  Session error: Out of range float values are not JSON compliant: nan\n",
      "  Session error: Out of range float values are not JSON compliant: nan\n",
      "  Processed 350/502 customers...\n",
      "    Sessions: 12386, Events: 77176\n",
      "  Processed 400/502 customers...\n",
      "    Sessions: 14341, Events: 89887\n",
      "  Processed 450/502 customers...\n",
      "    Sessions: 15987, Events: 100303\n",
      "  Processed 500/502 customers...\n",
      "    Sessions: 17541, Events: 109700\n",
      "\n",
      "============================================================\n",
      "INGESTION COMPLETE\n",
      "============================================================\n",
      "  Total Sessions: 17613 (115 errors)\n",
      "  Total Events: 110201 (12 errors)\n",
      "\n",
      "Sessions by segment:\n",
      "  active: 14107 sessions\n",
      "  at_risk: 2881 sessions\n",
      "  churned: 625 sessions\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RUN DATA INGESTION\n",
    "# ============================================================================\n",
    "#\n",
    "# This cell creates mobile app data in Supabase:\n",
    "# - App sessions (login events with device info)\n",
    "# - App events (user actions during sessions)\n",
    "#\n",
    "# Runtime: Approximately 5-10 minutes for 500 customers\n",
    "\n",
    "if supabase and erp_customers is not None:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Supabase Data Ingestion\")\n",
    "    print(f\"Target: {SUPABASE_URL}\")\n",
    "    print(f\"Customers to process: {len(erp_customers)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    sessions, events = create_sessions_and_events(supabase, erp_customers)\n",
    "else:\n",
    "    print(\"Cannot run ingestion:\")\n",
    "    if not supabase:\n",
    "        print(\"  - Not connected to Supabase\")\n",
    "    if erp_customers is None:\n",
    "        print(\"  - ERPNext customers not loaded\")\n",
    "    sessions, events = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Data Extraction\n",
    "\n",
    "Export Supabase data to CSV/JSON for Databricks ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sessions_from_supabase(supabase: Client) -> List[Dict]:\n",
    "    \"\"\"Extract all sessions from Supabase.\"\"\"\n",
    "    print(\"\\nExtracting Sessions...\")\n",
    "    \n",
    "    try:\n",
    "        result = supabase.table(\"app_sessions\").select(\"*\").execute()\n",
    "        sessions = result.data\n",
    "        print(f\"  Found {len(sessions)} sessions\")\n",
    "        return sessions\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_events_from_supabase(supabase: Client) -> List[Dict]:\n",
    "    \"\"\"Extract all events from Supabase.\"\"\"\n",
    "    print(\"\\nExtracting Events...\")\n",
    "    \n",
    "    try:\n",
    "        result = supabase.table(\"app_events\").select(\"*\").execute()\n",
    "        events = result.data\n",
    "        print(f\"  Found {len(events)} events\")\n",
    "        return events\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data: List[Dict], filename: str, output_dir: Path):\n",
    "    \"\"\"Save data to CSV file.\"\"\"\n",
    "    if not data:\n",
    "        print(f\"  No data for {filename}\")\n",
    "        return\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    # Get all unique keys\n",
    "    all_keys = set()\n",
    "    for record in data:\n",
    "        all_keys.update(record.keys())\n",
    "    fieldnames = sorted(list(all_keys))\n",
    "    \n",
    "    with open(filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    \n",
    "    print(f\"  Saved: {filename} ({len(data)} records)\")\n",
    "\n",
    "\n",
    "def save_to_json(data: List[Dict], filename: str, output_dir: Path):\n",
    "    \"\"\"Save data to JSON file.\"\"\"\n",
    "    if not data:\n",
    "        print(f\"  No data for {filename}\")\n",
    "        return\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"  Saved: {filename} ({len(data)} records)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Supabase Data Extraction\n",
      "Source: https://wtdspfddzqkpdaokgzys.supabase.co\n",
      "Output: c:\\Users\\SulaimanAhmed\\Desktop\\portfolio\\Banking project\\banking-churn-databricks\\notebooks\\exploration\\..\\..\\data\\raw\n",
      "============================================================\n",
      "\n",
      "Extracting Sessions...\n",
      "  Found 1000 sessions\n",
      "\n",
      "Extracting Events...\n",
      "  Found 1000 events\n",
      "\n",
      "============================================================\n",
      "Saving to CSV\n",
      "============================================================\n",
      "  Saved: sb_sessions.csv (1000 records)\n",
      "  Saved: sb_events.csv (1000 records)\n",
      "\n",
      "============================================================\n",
      "Saving to JSON\n",
      "============================================================\n",
      "  Saved: sb_sessions.json (1000 records)\n",
      "  Saved: sb_events.json (1000 records)\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Files saved to: c:\\Users\\SulaimanAhmed\\Desktop\\portfolio\\Banking project\\banking-churn-databricks\\notebooks\\exploration\\..\\..\\data\\raw\n",
      "\n",
      "  sb_sessions.csv : 1000 records\n",
      "  sb_events.csv   : 1000 records\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RUN DATA EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "if supabase:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Supabase Data Extraction\")\n",
    "    print(f\"Source: {SUPABASE_URL}\")\n",
    "    print(f\"Output: {OUTPUT_DIR.absolute()}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Extract data from Supabase\n",
    "    sb_sessions = extract_sessions_from_supabase(supabase)\n",
    "    sb_events = extract_events_from_supabase(supabase)\n",
    "    \n",
    "    # Save to CSV\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Saving to CSV\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    save_to_csv(sb_sessions, \"sb_sessions.csv\", OUTPUT_DIR)\n",
    "    save_to_csv(sb_events, \"sb_events.csv\", OUTPUT_DIR)\n",
    "    \n",
    "    # Save to JSON\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Saving to JSON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    save_to_json(sb_sessions, \"sb_sessions.json\", OUTPUT_DIR)\n",
    "    save_to_json(sb_events, \"sb_events.json\", OUTPUT_DIR)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXTRACTION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nFiles saved to: {OUTPUT_DIR.absolute()}\")\n",
    "    print(f\"\\n  sb_sessions.csv : {len(sb_sessions)} records\")\n",
    "    print(f\"  sb_events.csv   : {len(sb_events)} records\")\n",
    "else:\n",
    "    print(\"Not connected to Supabase - cannot extract data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook provides the complete Supabase digital channels data pipeline:\n",
    "\n",
    "1. **Configuration** - Auto-load credentials from .env\n",
    "2. **API Client** - Connect using supabase-py\n",
    "3. **Exploration** - Survey existing data\n",
    "4. **Ingestion** - Create sessions and events\n",
    "5. **Extraction** - Export to CSV/JSON\n",
    "\n",
    "### Churn Signal Implementation\n",
    "\n",
    "| Segment | Sessions | Events/Session | Pattern |\n",
    "|---------|----------|----------------|--------|\n",
    "| Active | 30-60 | 4-10 | Regular, engaged users |\n",
    "| At-Risk | 15-30 | 2-5 | Declining engagement |\n",
    "| Churned | 5-15 | 1-3 | Stopped before closing account |\n",
    "\n",
    "### Entity Resolution\n",
    "\n",
    "Customers are linked via **email**:\n",
    "```\n",
    "ERPNext.email_id = Supabase.user_email\n",
    "```\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "```\n",
    "data/raw/\n",
    "├── sb_sessions.csv    # App login sessions\n",
    "├── sb_sessions.json\n",
    "├── sb_events.csv      # User actions (churn signal!)\n",
    "└── sb_events.json\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Run Google Sheets legacy data generator\n",
    "2. Build Bronze layer in dbt\n",
    "\n",
    "---\n",
    "*Created for Banking Customer Churn Prediction POC*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
